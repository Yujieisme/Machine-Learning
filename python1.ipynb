{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(b,m,data):\n",
    "\n",
    "    totalError = 0\n",
    "    #Two ways to implement this\n",
    "    #first way\n",
    "    # for i in range(0,len(data)):\n",
    "    #     x = data[i,0]\n",
    "    #     y = data[i,1]\n",
    "    #\n",
    "    #     totalError += (y-(m*x+b))**2\n",
    "\n",
    "    #second way\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    totalError = (y-m*x-b)**2\n",
    "    totalError = np.sum(totalError,axis=0)\n",
    "\n",
    "    return totalError/float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(data,starting_b,starting_m,learning_rate,num_iter):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "\n",
    "    #gradient descent\n",
    "    for i in range(num_iter):\n",
    "        #update b and m with the new more accurate b and m by performing\n",
    "        # thie gradient step\n",
    "        b,m =compute_gradient(b,m,data,learning_rate)\n",
    "        if i%100==0:\n",
    "            print 'iter {0}:error={1}'.format(i,compute_error(b,m,data))\n",
    "    return [b,m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(b_current,m_current,data ,learning_rate):\n",
    "\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "\n",
    "    N = float(len(data))\n",
    "    #Two ways to implement this\n",
    "    #first way\n",
    "    # for i in range(0,len(data)):\n",
    "    #     x = data[i,0]\n",
    "    #     y = data[i,1]\n",
    "    #\n",
    "    #     #computing partial derivations of our error function\n",
    "    #     #b_gradient = -(2/N)*sum((y-(m*x+b))^2)\n",
    "    #     #m_gradient = -(2/N)*sum(x*(y-(m*x+b))^2)\n",
    "    #     b_gradient += -(2/N)*(y-((m_current*x)+b_current))\n",
    "    #     m_gradient += -(2/N) * x * (y-((m_current*x)+b_current))\n",
    "\n",
    "    #Vectorization implementation\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    b_gradient = -(2/N)*(y-m_current*x-b_current)\n",
    "    b_gradient = np.sum(b_gradient,axis=0)\n",
    "    m_gradient = -(2/N)*x*(y-m_current*x-b_current)\n",
    "    m_gradient = np.sum(m_gradient,axis=0)\n",
    "        #update our b and m values using out partial derivations\n",
    "\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "    return [new_b,new_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data,b,m):\n",
    "\n",
    "    #plottting\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    y_predict = m*x+b\n",
    "    pylab.plot(x,y,'o')\n",
    "    pylab.plot(x,y_predict,'k-')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_regression():\n",
    "    # get train data\n",
    "    data =np.loadtxt('data.csv',delimiter=',')\n",
    "\n",
    "    #define hyperparamters\n",
    "    #learning_rate is used for update gradient\n",
    "    #defint the number that will iteration\n",
    "    # define  y =mx+b\n",
    "    learning_rate = 0.001\n",
    "    initial_b =0.0\n",
    "    initial_m = 0.0\n",
    "    num_iter = 1000\n",
    "\n",
    "    #train model\n",
    "    #print b m error\n",
    "    print 'initial variables:\\n initial_b = {0}\\n intial_m = {1}\\n error of begin = {2} \\n'\\\n",
    "        .format(initial_b,initial_m,compute_error(initial_b,initial_m,data))\n",
    "\n",
    "    #optimizing b and m\n",
    "    [b ,m] = optimizer(data,initial_b,initial_m,learning_rate,num_iter)\n",
    "\n",
    "    #print final b m error\n",
    "    print 'final formula parmaters:\\n b = {1}\\n m={2}\\n error of end = {3} \\n'.format(num_iter,b,m,compute_error(b,m,data))\n",
    "\n",
    "    #plot result\n",
    "    plot_data(data,b,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "\n",
    "    Linear_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
